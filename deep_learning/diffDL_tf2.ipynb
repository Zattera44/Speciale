{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "real_type = tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            name = 'weights',\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"glorot_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name = 'bias',\n",
    "            shape=(self.units,), \n",
    "            initializer=\"zeros\", \n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return keras.activations.softplus(inputs) @ self.w + self.b\n",
    "\n",
    "class BackpropLayer(keras.layers.Layer):\n",
    "    def __init__(self, twin: ForwardLayer, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.twin = twin\n",
    "        self.units = self.twin.units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.twin.w\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, output=False):\n",
    "        z, zbar = inputs\n",
    "        if not output:\n",
    "            return zbar @ tf.transpose(self.twin.w) * keras.activations.sigmoid(z)\n",
    "        if output:\n",
    "            return zbar @ tf.transpose(self.twin.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_1 = ForwardLayer(units=4, name='forward_1')\n",
    "forward_2 = ForwardLayer(units=4, name='forward_2')\n",
    "forward_3 = ForwardLayer(units=4, name='forward_3')\n",
    "output = ForwardLayer(units=1, name='output')\n",
    "backprop_1 = BackpropLayer(twin=output, name='backprop_1')\n",
    "backprop_2 = BackpropLayer(twin=forward_3, name='backprop_2')\n",
    "backprop_3 = BackpropLayer(twin=forward_2, name='backprop_3')\n",
    "derivs = BackpropLayer(twin=forward_1, name='derivs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = keras.layers.Input(shape=(1,), name='input')\n",
    "z1 = forward_1(z0)\n",
    "z2 = forward_2(z1)\n",
    "z3 = forward_3(z2)\n",
    "y = output(z3)\n",
    "zbar4 = tf.ones_like(y)\n",
    "zbar3 = backprop_1(inputs=[z3,zbar4])\n",
    "zbar2 = backprop_2(inputs=[z2,zbar3])\n",
    "zbar1 = backprop_3(inputs=[z1,zbar2])\n",
    "derivs = derivs(inputs=[1,zbar1], output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=z0, outputs=[y,derivs])\n",
    "model.compile(loss=['mse','mse'], loss_weights=[0.5,0.5], optimizer=keras.optimizers.Adam(learning_rate=0.11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Savine notebook\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def bsPrice(spot, strike, vol, T):\n",
    "    d1 = (np.log(spot/strike) + 0.5 * vol * vol * T) / vol / np.sqrt(T)\n",
    "    d2 = d1 - vol * np.sqrt(T)\n",
    "    return spot * norm.cdf(d1) - strike * norm.cdf(d2)\n",
    "\n",
    "def bsDelta(spot, strike, vol, T):\n",
    "    d1 = (np.log(spot/strike) + 0.5 * vol * vol * T) / vol / np.sqrt(T)\n",
    "    return norm.cdf(d1)\n",
    "\n",
    "def bsVega(spot, strike, vol, T):\n",
    "    d1 = (np.log(spot/strike) + 0.5 * vol * vol * T) / vol / np.sqrt(T)\n",
    "    return spot * np.sqrt(T) * norm.pdf(d1)\n",
    "    \n",
    "class BlackScholes:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vol=0.2,\n",
    "                 T1=1, \n",
    "                 T2=2, \n",
    "                 K=1.10,\n",
    "                 volMult=1.5):\n",
    "        \n",
    "        self.spot = 1\n",
    "        self.vol = vol\n",
    "        self.T1 = T1\n",
    "        self.T2 = T2\n",
    "        self.K = K\n",
    "        self.volMult = volMult\n",
    "                        \n",
    "    def trainingSet(self, m, anti=True):\n",
    "            \n",
    "        returns = np.random.normal(size=[m, 2])\n",
    "\n",
    "        vol0 = self.vol * self.volMult\n",
    "        R1 = np.exp(-0.5*vol0*vol0*self.T1 + vol0*np.sqrt(self.T1)*returns[:,0])\n",
    "        R2 = np.exp(-0.5*self.vol*self.vol*(self.T2-self.T1) \\\n",
    "                    + self.vol*np.sqrt(self.T2-self.T1)*returns[:,1])\n",
    "        S1 = self.spot * R1\n",
    "        S2 = S1 * R2 \n",
    "\n",
    "        pay = np.maximum(0, S2 - self.K)\n",
    "        \n",
    "        if anti:\n",
    "            \n",
    "            R2a = np.exp(-0.5*self.vol*self.vol*(self.T2-self.T1) \\\n",
    "                    - self.vol*np.sqrt(self.T2-self.T1)*returns[:,1])\n",
    "            S2a = S1 * R2a             \n",
    "            paya = np.maximum(0, S2a - self.K)\n",
    "            \n",
    "            X = S1\n",
    "            Y = 0.5 * (pay + paya)\n",
    "    \n",
    "            Z1 =  np.where(S2 > self.K, R2, 0.0).reshape((-1,1)) \n",
    "            Z2 =  np.where(S2a > self.K, R2a, 0.0).reshape((-1,1)) \n",
    "            Z = 0.5 * (Z1 + Z2)\n",
    "                    \n",
    "        else:\n",
    "        \n",
    "            X = S1\n",
    "            Y = pay\n",
    "            \n",
    "            Z =  np.where(S2 > self.K, R2, 0.0).reshape((-1,1)) \n",
    "        \n",
    "        return X.reshape([-1,1]), Y.reshape([-1,1]), Z.reshape([-1,1])\n",
    "    \n",
    "    def testSet(self, lower=0.35, upper=1.65, num=100):\n",
    "        \n",
    "        spots = np.linspace(lower, upper, num).reshape((-1, 1))\n",
    "        prices = bsPrice(spots, self.K, self.vol, self.T2 - self.T1).reshape((-1, 1))\n",
    "        deltas = bsDelta(spots, self.K, self.vol, self.T2 - self.T1).reshape((-1, 1))\n",
    "        vegas = bsVega(spots, self.K, self.vol, self.T2 - self.T1).reshape((-1, 1))\n",
    "        return spots, spots, prices, deltas, vegas   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTest = 8192\n",
    "bs = BlackScholes()\n",
    "xTrain, yTrain, dydxTrain = bs.trainingSet(nTest)\n",
    "xTest, xAxis, yTest, dydxTest, vegas = bs.testSet(num=nTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "256/256 [==============================] - 1s 1ms/step - loss: 0.0573 - output_loss: 0.0272 - derivs_loss: 0.0874\n",
      "Epoch 2/100\n",
      "256/256 [==============================] - 0s 970us/step - loss: 0.0255 - output_loss: 0.0048 - derivs_loss: 0.0462\n",
      "Epoch 3/100\n",
      "256/256 [==============================] - 0s 922us/step - loss: 0.0249 - output_loss: 0.0045 - derivs_loss: 0.0454\n",
      "Epoch 4/100\n",
      "256/256 [==============================] - 0s 924us/step - loss: 0.0248 - output_loss: 0.0046 - derivs_loss: 0.0450\n",
      "Epoch 5/100\n",
      "256/256 [==============================] - 0s 918us/step - loss: 0.0258 - output_loss: 0.0050 - derivs_loss: 0.0467\n",
      "Epoch 6/100\n",
      "256/256 [==============================] - 0s 920us/step - loss: 0.0259 - output_loss: 0.0053 - derivs_loss: 0.0464\n",
      "Epoch 7/100\n",
      "256/256 [==============================] - 0s 928us/step - loss: 0.0260 - output_loss: 0.0064 - derivs_loss: 0.0457\n",
      "Epoch 8/100\n",
      "256/256 [==============================] - 0s 919us/step - loss: 0.0263 - output_loss: 0.0059 - derivs_loss: 0.0467\n",
      "Epoch 9/100\n",
      "256/256 [==============================] - 0s 902us/step - loss: 0.0263 - output_loss: 0.0056 - derivs_loss: 0.0471\n",
      "Epoch 10/100\n",
      "256/256 [==============================] - 0s 919us/step - loss: 0.0263 - output_loss: 0.0059 - derivs_loss: 0.0468\n",
      "Epoch 11/100\n",
      "256/256 [==============================] - 0s 924us/step - loss: 0.0255 - output_loss: 0.0056 - derivs_loss: 0.0455\n",
      "Epoch 12/100\n",
      "256/256 [==============================] - 0s 920us/step - loss: 0.0255 - output_loss: 0.0054 - derivs_loss: 0.0456\n",
      "Epoch 13/100\n",
      "256/256 [==============================] - 0s 911us/step - loss: 0.0257 - output_loss: 0.0054 - derivs_loss: 0.0460\n",
      "Epoch 14/100\n",
      "256/256 [==============================] - 0s 928us/step - loss: 0.0257 - output_loss: 0.0051 - derivs_loss: 0.0462\n",
      "Epoch 15/100\n",
      "256/256 [==============================] - 0s 892us/step - loss: 0.0258 - output_loss: 0.0056 - derivs_loss: 0.0460\n",
      "Epoch 16/100\n",
      "256/256 [==============================] - 0s 925us/step - loss: 0.0257 - output_loss: 0.0051 - derivs_loss: 0.0462\n",
      "Epoch 17/100\n",
      "256/256 [==============================] - 0s 915us/step - loss: 0.0252 - output_loss: 0.0052 - derivs_loss: 0.0451\n",
      "Epoch 18/100\n",
      "256/256 [==============================] - 0s 912us/step - loss: 0.0250 - output_loss: 0.0047 - derivs_loss: 0.0453\n",
      "Epoch 19/100\n",
      "256/256 [==============================] - 0s 910us/step - loss: 0.0250 - output_loss: 0.0047 - derivs_loss: 0.0453\n",
      "Epoch 20/100\n",
      "256/256 [==============================] - 0s 913us/step - loss: 0.0256 - output_loss: 0.0055 - derivs_loss: 0.0457\n",
      "Epoch 21/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0252 - output_loss: 0.0055 - derivs_loss: 0.0448\n",
      "Epoch 22/100\n",
      "256/256 [==============================] - 0s 898us/step - loss: 0.0259 - output_loss: 0.0049 - derivs_loss: 0.0468\n",
      "Epoch 23/100\n",
      "256/256 [==============================] - 0s 921us/step - loss: 0.0257 - output_loss: 0.0057 - derivs_loss: 0.0456\n",
      "Epoch 24/100\n",
      "256/256 [==============================] - 0s 912us/step - loss: 0.0257 - output_loss: 0.0054 - derivs_loss: 0.0460\n",
      "Epoch 25/100\n",
      "256/256 [==============================] - 0s 936us/step - loss: 0.0250 - output_loss: 0.0053 - derivs_loss: 0.0447\n",
      "Epoch 26/100\n",
      "256/256 [==============================] - 0s 904us/step - loss: 0.0258 - output_loss: 0.0057 - derivs_loss: 0.0459\n",
      "Epoch 27/100\n",
      "256/256 [==============================] - 0s 914us/step - loss: 0.0247 - output_loss: 0.0052 - derivs_loss: 0.0443\n",
      "Epoch 28/100\n",
      "256/256 [==============================] - 0s 898us/step - loss: 0.0252 - output_loss: 0.0054 - derivs_loss: 0.0450\n",
      "Epoch 29/100\n",
      "256/256 [==============================] - 0s 890us/step - loss: 0.0254 - output_loss: 0.0051 - derivs_loss: 0.0456\n",
      "Epoch 30/100\n",
      "256/256 [==============================] - 0s 923us/step - loss: 0.0263 - output_loss: 0.0056 - derivs_loss: 0.0469\n",
      "Epoch 31/100\n",
      "256/256 [==============================] - 0s 910us/step - loss: 0.0248 - output_loss: 0.0051 - derivs_loss: 0.0444\n",
      "Epoch 32/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0247 - output_loss: 0.0050 - derivs_loss: 0.0444\n",
      "Epoch 33/100\n",
      "256/256 [==============================] - 0s 972us/step - loss: 0.0253 - output_loss: 0.0055 - derivs_loss: 0.0451\n",
      "Epoch 34/100\n",
      "256/256 [==============================] - 0s 905us/step - loss: 0.0242 - output_loss: 0.0045 - derivs_loss: 0.0440\n",
      "Epoch 35/100\n",
      "256/256 [==============================] - 0s 886us/step - loss: 0.0268 - output_loss: 0.0070 - derivs_loss: 0.0467\n",
      "Epoch 36/100\n",
      "256/256 [==============================] - 0s 922us/step - loss: 0.0254 - output_loss: 0.0055 - derivs_loss: 0.0453\n",
      "Epoch 37/100\n",
      "256/256 [==============================] - 0s 884us/step - loss: 0.0248 - output_loss: 0.0048 - derivs_loss: 0.0448\n",
      "Epoch 38/100\n",
      "256/256 [==============================] - 0s 912us/step - loss: 0.0263 - output_loss: 0.0060 - derivs_loss: 0.0467\n",
      "Epoch 39/100\n",
      "256/256 [==============================] - 0s 910us/step - loss: 0.0251 - output_loss: 0.0051 - derivs_loss: 0.0452\n",
      "Epoch 40/100\n",
      "256/256 [==============================] - 0s 926us/step - loss: 0.0253 - output_loss: 0.0052 - derivs_loss: 0.0454\n",
      "Epoch 41/100\n",
      "256/256 [==============================] - 0s 915us/step - loss: 0.0250 - output_loss: 0.0053 - derivs_loss: 0.0447\n",
      "Epoch 42/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0253 - output_loss: 0.0052 - derivs_loss: 0.0454\n",
      "Epoch 43/100\n",
      "256/256 [==============================] - 0s 902us/step - loss: 0.0251 - output_loss: 0.0050 - derivs_loss: 0.0451\n",
      "Epoch 44/100\n",
      "256/256 [==============================] - 0s 918us/step - loss: 0.0245 - output_loss: 0.0046 - derivs_loss: 0.0445\n",
      "Epoch 45/100\n",
      "256/256 [==============================] - 0s 904us/step - loss: 0.0261 - output_loss: 0.0057 - derivs_loss: 0.0465\n",
      "Epoch 46/100\n",
      "256/256 [==============================] - 0s 911us/step - loss: 0.0246 - output_loss: 0.0046 - derivs_loss: 0.0447\n",
      "Epoch 47/100\n",
      "256/256 [==============================] - 0s 918us/step - loss: 0.0248 - output_loss: 0.0048 - derivs_loss: 0.0449\n",
      "Epoch 48/100\n",
      "256/256 [==============================] - 0s 937us/step - loss: 0.0249 - output_loss: 0.0050 - derivs_loss: 0.0449\n",
      "Epoch 49/100\n",
      "256/256 [==============================] - 0s 913us/step - loss: 0.0252 - output_loss: 0.0057 - derivs_loss: 0.0447\n",
      "Epoch 50/100\n",
      "256/256 [==============================] - 0s 916us/step - loss: 0.0245 - output_loss: 0.0050 - derivs_loss: 0.0440\n",
      "Epoch 51/100\n",
      "256/256 [==============================] - 0s 903us/step - loss: 0.0250 - output_loss: 0.0051 - derivs_loss: 0.0448\n",
      "Epoch 52/100\n",
      "256/256 [==============================] - 0s 916us/step - loss: 0.0267 - output_loss: 0.0055 - derivs_loss: 0.0478\n",
      "Epoch 53/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0245 - output_loss: 0.0046 - derivs_loss: 0.0445\n",
      "Epoch 54/100\n",
      "256/256 [==============================] - 0s 912us/step - loss: 0.0247 - output_loss: 0.0051 - derivs_loss: 0.0443\n",
      "Epoch 55/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0247 - output_loss: 0.0049 - derivs_loss: 0.0446\n",
      "Epoch 56/100\n",
      "256/256 [==============================] - 0s 913us/step - loss: 0.0250 - output_loss: 0.0051 - derivs_loss: 0.0449\n",
      "Epoch 57/100\n",
      "256/256 [==============================] - 0s 917us/step - loss: 0.0243 - output_loss: 0.0043 - derivs_loss: 0.0442\n",
      "Epoch 58/100\n",
      "256/256 [==============================] - 0s 917us/step - loss: 0.0246 - output_loss: 0.0048 - derivs_loss: 0.0444\n",
      "Epoch 59/100\n",
      "256/256 [==============================] - 0s 904us/step - loss: 0.0262 - output_loss: 0.0069 - derivs_loss: 0.0456\n",
      "Epoch 60/100\n",
      "256/256 [==============================] - 0s 918us/step - loss: 0.0337 - output_loss: 0.0186 - derivs_loss: 0.0489\n",
      "Epoch 61/100\n",
      "256/256 [==============================] - 0s 913us/step - loss: 0.0264 - output_loss: 0.0080 - derivs_loss: 0.0449\n",
      "Epoch 62/100\n",
      "256/256 [==============================] - 0s 901us/step - loss: 0.0441 - output_loss: 0.0297 - derivs_loss: 0.0585\n",
      "Epoch 63/100\n",
      "256/256 [==============================] - 0s 984us/step - loss: 0.0391 - output_loss: 0.0331 - derivs_loss: 0.0451\n",
      "Epoch 64/100\n",
      "256/256 [==============================] - 0s 919us/step - loss: 0.0393 - output_loss: 0.0337 - derivs_loss: 0.0449\n",
      "Epoch 65/100\n",
      "256/256 [==============================] - 0s 907us/step - loss: 0.0386 - output_loss: 0.0331 - derivs_loss: 0.0440\n",
      "Epoch 66/100\n",
      "256/256 [==============================] - 0s 912us/step - loss: 0.0386 - output_loss: 0.0335 - derivs_loss: 0.0438\n",
      "Epoch 67/100\n",
      "256/256 [==============================] - 0s 908us/step - loss: 0.0382 - output_loss: 0.0330 - derivs_loss: 0.0434\n",
      "Epoch 68/100\n",
      "256/256 [==============================] - 0s 919us/step - loss: 0.0386 - output_loss: 0.0332 - derivs_loss: 0.0441\n",
      "Epoch 69/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0385 - output_loss: 0.0336 - derivs_loss: 0.0433\n",
      "Epoch 70/100\n",
      "256/256 [==============================] - 0s 924us/step - loss: 0.0389 - output_loss: 0.0339 - derivs_loss: 0.0438\n",
      "Epoch 71/100\n",
      "256/256 [==============================] - 0s 897us/step - loss: 0.0380 - output_loss: 0.0331 - derivs_loss: 0.0430\n",
      "Epoch 72/100\n",
      "256/256 [==============================] - 0s 917us/step - loss: 0.0384 - output_loss: 0.0332 - derivs_loss: 0.0436\n",
      "Epoch 73/100\n",
      "256/256 [==============================] - 0s 912us/step - loss: 0.0378 - output_loss: 0.0332 - derivs_loss: 0.0425\n",
      "Epoch 74/100\n",
      "256/256 [==============================] - 0s 917us/step - loss: 0.0384 - output_loss: 0.0333 - derivs_loss: 0.0435\n",
      "Epoch 75/100\n",
      "256/256 [==============================] - 0s 913us/step - loss: 0.0386 - output_loss: 0.0329 - derivs_loss: 0.0443\n",
      "Epoch 76/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0383 - output_loss: 0.0333 - derivs_loss: 0.0432\n",
      "Epoch 77/100\n",
      "256/256 [==============================] - 0s 905us/step - loss: 0.0383 - output_loss: 0.0332 - derivs_loss: 0.0435\n",
      "Epoch 78/100\n",
      "256/256 [==============================] - 0s 924us/step - loss: 0.0390 - output_loss: 0.0341 - derivs_loss: 0.0438\n",
      "Epoch 79/100\n",
      "256/256 [==============================] - 0s 906us/step - loss: 0.0386 - output_loss: 0.0333 - derivs_loss: 0.0438\n",
      "Epoch 80/100\n",
      "256/256 [==============================] - 0s 918us/step - loss: 0.0383 - output_loss: 0.0339 - derivs_loss: 0.0428\n",
      "Epoch 81/100\n",
      "256/256 [==============================] - 0s 919us/step - loss: 0.0382 - output_loss: 0.0333 - derivs_loss: 0.0431\n",
      "Epoch 82/100\n",
      "256/256 [==============================] - 0s 915us/step - loss: 0.0389 - output_loss: 0.0328 - derivs_loss: 0.0450\n",
      "Epoch 83/100\n",
      "256/256 [==============================] - 0s 908us/step - loss: 0.0389 - output_loss: 0.0338 - derivs_loss: 0.0439\n",
      "Epoch 84/100\n",
      "256/256 [==============================] - 0s 907us/step - loss: 0.0383 - output_loss: 0.0334 - derivs_loss: 0.0432\n",
      "Epoch 85/100\n",
      "256/256 [==============================] - 0s 910us/step - loss: 0.0383 - output_loss: 0.0333 - derivs_loss: 0.0433\n",
      "Epoch 86/100\n",
      "256/256 [==============================] - 0s 914us/step - loss: 0.0385 - output_loss: 0.0338 - derivs_loss: 0.0432\n",
      "Epoch 87/100\n",
      "256/256 [==============================] - 0s 918us/step - loss: 0.0384 - output_loss: 0.0330 - derivs_loss: 0.0438\n",
      "Epoch 88/100\n",
      "256/256 [==============================] - 0s 922us/step - loss: 0.0389 - output_loss: 0.0335 - derivs_loss: 0.0443\n",
      "Epoch 89/100\n",
      "256/256 [==============================] - 0s 894us/step - loss: 0.0382 - output_loss: 0.0334 - derivs_loss: 0.0430\n",
      "Epoch 90/100\n",
      "256/256 [==============================] - 0s 931us/step - loss: 0.0384 - output_loss: 0.0335 - derivs_loss: 0.0432\n",
      "Epoch 91/100\n",
      "256/256 [==============================] - 0s 909us/step - loss: 0.0384 - output_loss: 0.0338 - derivs_loss: 0.0429\n",
      "Epoch 92/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0384 - output_loss: 0.0332 - derivs_loss: 0.0437\n",
      "Epoch 93/100\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0380 - output_loss: 0.0330 - derivs_loss: 0.0429\n",
      "Epoch 94/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0381 - output_loss: 0.0331 - derivs_loss: 0.0431\n",
      "Epoch 95/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0381 - output_loss: 0.0330 - derivs_loss: 0.0432\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.0385 - output_loss: 0.0334 - derivs_loss: 0.0435\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0383 - output_loss: 0.0333 - derivs_loss: 0.0432\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0383 - output_loss: 0.0334 - derivs_loss: 0.0431\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0380 - output_loss: 0.0332 - derivs_loss: 0.0429\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.0385 - output_loss: 0.0337 - derivs_loss: 0.0433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    xTrain, [yTrain, dydxTrain], epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 0s 775us/step - loss: 0.0153 - output_loss: 0.0298 - derivs_loss: 8.5479e-04\n"
     ]
    }
   ],
   "source": [
    "total_loss, y_loss, dydx_loss = model.evaluate(\n",
    "    xTest, [yTest, dydxTest]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12387343594524104 0.172726569808124 0.02923682635241666\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(total_loss),np.sqrt(y_loss),np.sqrt(dydx_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, dydx_pred = model.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16ea4e350>]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dydx_pred)\n",
    "plt.plot(dydxTest)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6314f1dd6a1867270512df5dbaf0da944fed172eba7544c32ea9917be2637492"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('thematrix')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
